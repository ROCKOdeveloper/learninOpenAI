{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings con OpenAI\n",
    " Embedding en procesamiento de lenguaje natural es una técnica que se usa para representar palabras como vectores numéricos en un espacio n-dimensional, donde n es el número de características que se quieran representar. Se busca que estas representaciones capturen el significado semántico y sintáctico de las palabras y, por lo tanto, que palabras similares tengan vectores similares. \n",
    " \n",
    " Estos embeddings se utilizan después como entrada en modelos de aprendizaje automático para realizar tareas de procesamiento de lenguaje natural, como clasificación de texto o traducción automática."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de comenzar importamos las dependencias necesarias\n",
    "\n",
    "import openai # Librería de OpenAI para acceso a su API\n",
    "import gradio as gr # Librería para crear la interfaz gráfica\n",
    "import pandas as pd # Librería para trabajar con DataFrames en Python\n",
    "\n",
    "from openai.embeddings_utils import get_embedding # Función para obtener la representación vectorial de un texto\n",
    "from openai.embeddings_utils import cosine_similarity # Función para calcular la similitud coseno entre dos embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la API Key para vincular el cuaderno con nuestra cuenta de OpenAI\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cómo usar embeddings\n",
    "Al hacer embedding de un dato, lo estamos convirtiendo a un vector numérico, datos similares estarán más cercanos entre si cuando semanticamente son similares."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como ejemplo, en una lista de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos una lista\n",
    "palabras = [\"casa\", \"perro\", \"gato\", \"lobo\", \"leon\", \"zebra\", \"tigre\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un diccionario vacío\n",
    "diccionario = {}\n",
    "# Iteramos a través de una lista de palabras\n",
    "for i in palabras:\n",
    "    diccionario[i] = get_embedding(i, engine=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se llama a la función keys() del diccionario para obtener una vista iterable de sus claves.\n",
    "diccionario.keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora lo vemos con una palabra en específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define la palabra 'gato'\n",
    "palabra = \"perro\"\n",
    "\n",
    "# Imprime los primeros 10 valores del diccionario asociado a la palabra 'gato'\n",
    "print(\"Primeros 10 valores de {}:\\n\".format(palabra), diccionario[palabra][:10])\n",
    "\n",
    "# Imprime un salto de línea\n",
    "print(\"\\n\")\n",
    "\n",
    "# Imprime el número de dimensiones del dato embebido\n",
    "print(\"Número de dimensiones del dato embebido\", len(diccionario[palabra]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparar dos embeddings\n",
    "Debido a que los embeddings son una representacion vectorial de los datos en un espacio latente, podemos medir la distancia entre dos vectores y asi obtener que tan similares son. Podemos comparar una palabra nueva o alguna de las que ya fueron embebidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos la palabra nueva a comparar\n",
    "n_palabra = \"agujero negro\"\n",
    "\n",
    "# Definimos la palabra en el diccionario con la que compararemos la nueva palabra\n",
    "palabra_comparar = \"perro\"\n",
    "\n",
    "# Obtenemos un vector de embedding de la nueva palabra, utilizando el motor de \"text-embedding-ada-002\"\n",
    "n_palabra_embed = get_embedding(n_palabra, engine=\"text-embedding-ada-002\")\n",
    "\n",
    "# Obtenemos la similitud coseno entre el vector de embedding de la palabra a comparar en el diccionario y el vector de embedding de la nueva palabra\n",
    "similitud = cosine_similarity(diccionario[palabra_comparar], n_palabra_embed)\n",
    "\n",
    "# Imprimimos la similitud coseno para mostrar el resultado\n",
    "print(similitud)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sumar embeddings\n",
    "Como los vectores contienen valores numericos, podemos sumarlos y el resultado será un nuevo vector de un concepto que una los elementos sumados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar dos listas usando pandas\n",
    "sumados = (pd.DataFrame(diccionario[\"leon\"])) + (pd.DataFrame(diccionario[\"zebra\"]))\n",
    "\n",
    "# Calcular la longitud de la lista sumada\n",
    "len(sumados)\n",
    "\n",
    "# Calcular la similitud coseno entre cada lista del diccionario y la lista sumada\n",
    "for key, value in diccionario.items():\n",
    "    print(key, \":\", cosine_similarity(diccionario[key], sumados))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicado en un Chatbot\n",
    "\n",
    "Usaremos Gradio para hacer una interfaz básica donde podremos hacer preguntas y obtendremos una respuesta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea embeddings para cada texto en el archivo CSV\n",
    "\n",
    "# Se define la función `embed_text` con un argumento opcional path igual a \"texto.csv\"\n",
    "def embed_text(path=\"texto.csv\"):\n",
    "    # Se lee el archivo csv ubicado en `path` y se guarda en un DataFrame llamado `conocimiento_df`\n",
    "    conocimiento_df = pd.read_csv(path)\n",
    "    \n",
    "    # Se agrega una columna `Embedding` al DataFrame, que se rellena utilizando el método `apply` y\n",
    "    # una función lambda que llama a otra función llamada `get_embedding` con el motor de embedding 'text-embedding-ada-002'\n",
    "    conocimiento_df['Embedding'] = conocimiento_df['texto'].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
    "    \n",
    "    # Se guarda el DataFrame con la nueva columna en un nuevo archivo csv 'embeddings.csv'\n",
    "    conocimiento_df.to_csv('embeddings.csv')\n",
    "    \n",
    "    # Se devuelve el DataFrame `conocimiento_df`\n",
    "    return conocimiento_df\n",
    "\n",
    "\n",
    "# Busca los textos más similares a una búsqueda dada y devuelve los resultados junto con los embeddings correspondientes.\n",
    "\n",
    "# Definición de la función 'buscar'\n",
    "def buscar(busqueda, datos, n_resultados=5):\n",
    "    # Obtención del vector de incrustación (embedding) de la búsqueda usando el motor 'text-embedding-ada-002'\n",
    "    busqueda_embed = get_embedding(busqueda, engine=\"text-embedding-ada-002\")\n",
    "    \n",
    "    # Cálculo de la similitud coseno entre el embedding de la búsqueda y cada uno de los embeddings de los datos.\n",
    "    datos[\"Similitud\"] = datos['Embedding'].apply(lambda x: cosine_similarity(x, busqueda_embed))\n",
    "    \n",
    "    # Ordenar los datos según la similitud, de mayor a menor.\n",
    "    datos = datos.sort_values(\"Similitud\", ascending=False)\n",
    "    \n",
    "    # Selección de los 'n_resultados' datos más similares, y regresados los campos: 'texto', 'Similitud', 'Embedding'.\n",
    "    return datos.iloc[:n_resultados][[\"texto\", \"Similitud\", \"Embedding\"]]\n",
    "\n",
    "# Llamamos la funcion con un archivo csv como argumento y almacenamos los resultados en \"texto_emb\"\n",
    "texto_emb = embed_text(\"./chatbot_qa.csv\")\n",
    "\n",
    "### Crea una interfaz de usuario para buscar en el archivo CSV\n",
    "\n",
    "# Define los elementos de la interfaz (cuadro de búsqueda, botón y resultados)\n",
    "with gr.Blocks() as demo:\n",
    "    busqueda = gr.Textbox(label=\"Buscar\")\n",
    "    output = gr.DataFrame(headers=['texto'])\n",
    "    greet_btn = gr.Button(\"Preguntar\")\n",
    "\n",
    "    # Define qué función se llamará cuando se haga clic en el botón \n",
    "    # y qué entradas y salidas utilizará para obtener y mostrar los resultados. \n",
    "    greet_btn.click(fn=buscar, inputs=[busqueda, gr.DataFrame(texto_emb)], outputs=output)\n",
    "\n",
    "# Muestra la interfaz, de manera local y publica\n",
    "demo.launch(share=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procesar datos de un PDF\n",
    "Haremos ahora un ejemplo donde leemos un PDF para poder hacer preguntas y traer un exctracto del PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de comenzar debemos installar Lanchain (por estudiar)\n",
    "# pip install langchain pypdf\n",
    "# Importamos las librerias necesarias\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una instancia de la clase PyPDFLoader y le proporcionamos la ruta del archivo a cargar\n",
    "loader = PyPDFLoader(\"./mtg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el archivo y lo dividimos en páginas usando la instancia de PyPDFLoader\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionemos una página del contenido del PDF\n",
    "pages[3].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un objeto que va a hacer los cortes en el texto, cada 300 caracteres hará un salto de linea\n",
    "split = CharacterTextSplitter(chunk_size=300, separator = '.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se llama a la función 'split_documents' con el argumento 'pages'\n",
    "# y el resultado se guarda en la variable 'textos'\n",
    "textos = split.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimimos el contenido, el primero\n",
    "print(textos[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una lista que contiene la parte de \"page-content\" de cada objeto en la lista \"texto\"\n",
    "textos = [str(i.page_content) for i in textos] \n",
    "# Creamos un dataframe llamado \"parrafos\" a partir de la lista \"texto\" y nombramos la comumna \"texto\"\n",
    "parrafos = pd.DataFrame(textos, columns=[\"texto\"])\n",
    "# Imprimimos el dataframe \"parrafos\" en la consola\n",
    "print(parrafos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una nueva columna llamada 'Embedding' que contiene los embeddings de los párrafos procesados con el motor 'text-embedding-ada-002'\n",
    "parrafos['Embedding'] = parrafos[\"texto\"].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
    "# Guardamos el dataframe modificado en un archivo csv llamado mtg.csv\n",
    "parrafos.to_csv('MTG.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Por detallar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La misma funcion del chatbot de pregunts y respuestas\n",
    "def embed_text(path=\"mtg.pdf\"):\n",
    "    conocimiento_df = pd.read_csv(path)\n",
    "    conocimiento_df['Embedding'] = conocimiento_df['texto'].apply(lambda x: get_embedding(x, engine='text-embedding-ada-002'))\n",
    "    conocimiento_df.to_csv('mtg-embeddings.csv')\n",
    "    return conocimiento_df\n",
    "\n",
    "def buscar(busqueda, datos, n_resultados=5):\n",
    "    busqueda_embed = get_embedding(busqueda, engine=\"text-embedding-ada-002\")\n",
    "    datos[\"Similitud\"] = datos['Embedding'].apply(lambda x: cosine_similarity(x, busqueda_embed))\n",
    "    datos = datos.sort_values(\"Similitud\", ascending=False)\n",
    "    return datos.iloc[:n_resultados][[\"texto\", \"Similitud\", \"Embedding\"]]\n",
    "\n",
    "texto_emb = parrafos\n",
    "with gr.Blocks() as demo:\n",
    "    busqueda = gr.Textbox(label=\"Buscar\")\n",
    "    output = gr.DataFrame(headers=['texto'])\n",
    "    greet_btn = gr.Button(\"Preguntar\")\n",
    "    greet_btn.click(fn=buscar, inputs=[busqueda, gr.DataFrame(texto_emb)], outputs=output)\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.16 ('gpt3')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e3e99415c7ce2cb9b8857283077fa90c1d7ffec737ddc9f365b1225d7f13a404"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
